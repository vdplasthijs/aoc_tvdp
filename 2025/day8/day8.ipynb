{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os, sys \n",
    "sys.path.append('..')\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import aoc_utils as au\n",
    "import math \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input has 1000 rows and 15 cols\n"
     ]
    }
   ],
   "source": [
    "input_text = au.read_txt_file_lines('input.txt')\n",
    "n_rows = len(input_text)\n",
    "n_cols = len(input_text[0])\n",
    "# for ii in range(1, n_rows):\n",
    "#     assert len(input_text[ii]) == n_cols, f'row {ii} has {len(input_text[ii])} cols, not {n_cols}'\n",
    "print(f'input has {n_rows} rows and {n_cols} cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([np.array([int(x) for x in k.split(',')]) for k in input_text])\n",
    "n_points = len(points)\n",
    "\n",
    "def dist_3d(x, y):\n",
    "    '''For this exercise sqrt isn't needed'''\n",
    "    return np.sum(np.power(x - y, 2))\n",
    "    # return np.sqrt(np.sum(np.power(x - y, 2)))\n",
    "\n",
    "dist_mat = np.array([[dist_3d(x, y) for x in points] for y in points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_connections = 1000 \n",
    "dist_mat[np.arange(n_points), np.arange(n_points)] = np.max(dist_mat)\n",
    "graph = np.zeros_like(dist_mat)\n",
    "graph[dist_mat <= np.sort(np.ravel(dist_mat))[2 * n_connections - 1]] = 1\n",
    "assert np.sum(graph) == 2 * n_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127551\n"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "from collections import deque \n",
    "points_unassigned = set(range(n_points))\n",
    "\n",
    "while len(points_unassigned) > 0:\n",
    "    p = points_unassigned.pop()\n",
    "    new_cluster = set()\n",
    "    queue = deque([p])\n",
    "    \n",
    "    while len(queue) > 0:\n",
    "        q = queue.popleft()\n",
    "        if q in new_cluster:\n",
    "            continue \n",
    "        new_cluster.add(int(q))\n",
    "        if q in points_unassigned:\n",
    "            points_unassigned.remove(q)\n",
    "        for u in np.where(graph[q])[0]:\n",
    "            queue.append(u)\n",
    "        \n",
    "    clusters.append(new_cluster)\n",
    "\n",
    "size_clusters = sorted([len(c) for c in clusters])[::-1]\n",
    "print(size_clusters[0] * size_clusters[1] * size_clusters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.array([[dist_3d(x, y) for x in points] for y in points])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kind of by accident I ended up doing this 2 ways:\n",
    "\n",
    "1. Slow (10 sec): full graph check\n",
    "2. Pretty fast (0.3 check): merge cluster sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got it\n",
      "2347225200\n"
     ]
    }
   ],
   "source": [
    "points_sorted = []\n",
    "for i_r, r in enumerate(dist_mat):\n",
    "    for i_c, c in enumerate(r[:i_r + 1]):\n",
    "        points_sorted.append((int(c), i_r, i_c))\n",
    "\n",
    "points_sorted = sorted(points_sorted)\n",
    "graph = np.zeros((n_points, n_points), dtype=int)\n",
    "graph[np.arange(n_points), np.arange(n_points)] = 1\n",
    "\n",
    "ii = 0\n",
    "max_iter = 10000\n",
    "best_est = 0\n",
    "\n",
    "connections = {k: set([k]) for k in range(n_points)}\n",
    "points_visited = set() \n",
    "keep_going = True \n",
    "while keep_going:\n",
    "    _, i_r, i_c = points_sorted[ii]\n",
    "    graph[i_r, i_c] = 1\n",
    "    graph[i_c, i_r] = 1\n",
    "    \n",
    "    connections[i_c].add(i_r)\n",
    "    connections[i_r].add(i_c)\n",
    "\n",
    "    if i_c in points_visited and i_r in points_visited:\n",
    "        pass \n",
    "    else:\n",
    "        ## Go through full graph and check how many points were visited by the end\n",
    "        points_visited = set() \n",
    "        queue = deque([i_c, i_r])\n",
    "\n",
    "        while len(queue) > 0:\n",
    "            p = queue.popleft()\n",
    "            points_visited.add(p)\n",
    "            for q in connections[p]:\n",
    "                if q not in points_visited:\n",
    "                    queue.append(q) \n",
    "\n",
    "        if len(points_visited) == n_points:\n",
    "            print('got it')\n",
    "            keep_going = False\n",
    "            break\n",
    "        elif len(points_visited) > best_est:\n",
    "                # print(ii, best_est)\n",
    "                best_est = len(points_visited)\n",
    "\n",
    "    ii += 1\n",
    "    if ii > max_iter:\n",
    "        print('max iter')\n",
    "        break \n",
    "\n",
    "print(points[i_r, 0] * points[i_c, 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2347225200\n"
     ]
    }
   ],
   "source": [
    "points_sorted = []\n",
    "for i_r, r in enumerate(dist_mat):\n",
    "    for i_c, c in enumerate(r[:i_r + 1]):\n",
    "        points_sorted.append((int(c), i_r, i_c))\n",
    "\n",
    "points_sorted = sorted(points_sorted)\n",
    "graph = np.zeros((n_points, n_points), dtype=int)\n",
    "graph[np.arange(n_points), np.arange(n_points)] = 1\n",
    "\n",
    "ii = 0\n",
    "max_iter = 10000\n",
    "best_est = 0\n",
    "\n",
    "clusters = [] \n",
    "keep_going = True \n",
    "\n",
    "while keep_going:\n",
    "    _, i_r, i_c = points_sorted[ii]\n",
    "    graph[i_r, i_c] = 1\n",
    "    graph[i_c, i_r] = 1\n",
    "    \n",
    "    ## Merge clusters (if needed) of the two points\n",
    "    ind_clusters_merge = []\n",
    "    for ind_c, c in enumerate(clusters):\n",
    "        if i_r in c or i_c in c:\n",
    "            ind_clusters_merge.append(ind_c)\n",
    "    \n",
    "    if len(ind_clusters_merge) == 0:\n",
    "        clusters.append(set([i_r, i_c]))\n",
    "    elif len(ind_clusters_merge) == 1:\n",
    "        clusters[ind_c].add(i_r)\n",
    "        clusters[ind_c].add(i_c)\n",
    "    elif len(ind_clusters_merge) == 2:\n",
    "        new_c = clusters[ind_clusters_merge[0]].union(clusters[ind_clusters_merge[1]])\n",
    "        clusters = [c for ind_c, c in enumerate(clusters) if ind_c not in ind_clusters_merge]\n",
    "        clusters.append(new_c)\n",
    "        if len(new_c) == n_points:\n",
    "            keep_going = False\n",
    "    else:\n",
    "        ValueError\n",
    "\n",
    "    ii += 1\n",
    "\n",
    "\n",
    "print(points[i_r, 0] * points[i_c, 0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aether",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
