{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os, sys \n",
    "sys.path.append('..')\n",
    "from collections import deque, defaultdict\n",
    "import copy\n",
    "import itertools\n",
    "import aoc_utils as au\n",
    "import math \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input has 140 rows and 140 cols\n"
     ]
    }
   ],
   "source": [
    "input_text = au.read_txt_file_lines()\n",
    "n_rows = len(input_text)\n",
    "n_cols = len(input_text[0])\n",
    "for ii in range(1, n_rows):\n",
    "    assert len(input_text[ii]) == n_cols, f'row {ii} has {len(input_text[ii])} cols, not {n_cols}'\n",
    "print(f'input has {n_rows} rows and {n_cols} cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "visited = set()\n",
    "regions = list()\n",
    "results = list()\n",
    "\n",
    "def in_bounds(x, y):\n",
    "    if x >= 0 and x < n_rows and y >= 0 and y < n_cols:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def find_region(x, y):\n",
    "    seen_perim = set()\n",
    "    region = [(x, y)]\n",
    "    visited.add((x, y))\n",
    "    crop = input_text[x][y]\n",
    "\n",
    "    ## BFS search\":\n",
    "    queue = deque([(x + d[0], y + d[1], d) for d in dirs])\n",
    "\n",
    "    while len(queue) > 0:\n",
    "        (xn,  yn, d_old) = queue.popleft()    \n",
    "        if not in_bounds(xn, yn):\n",
    "            seen_perim.add((xn, yn, d_old))  # save old d to account for same border tile from different angles (= different perimeter tiles)\n",
    "            continue \n",
    "\n",
    "        cn = input_text[xn][yn]\n",
    "        if cn != crop:\n",
    "            seen_perim.add((xn, yn, d_old))\n",
    "            continue\n",
    "\n",
    "        if (xn, yn) in visited:\n",
    "            continue \n",
    "\n",
    "        region.append((xn, yn))\n",
    "        visited.add((xn, yn))\n",
    "        for d in dirs:\n",
    "            queue.append((xn + d[0], yn + d[1], d))\n",
    "\n",
    "    results.append((len(region), len(seen_perim)))\n",
    "    regions.append((region, seen_perim))\n",
    "\n",
    "for i_r, r in enumerate(input_text):\n",
    "    for i_c, el in enumerate(r):\n",
    "        if (i_r, i_c) in visited:\n",
    "            continue\n",
    "\n",
    "        find_region(i_r, i_c)\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1473408"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([r[0] * r[1] for r in results])\n",
    "# regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886364"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perim_converter(perim_set):\n",
    "    '''Convert existing set of perimeters to new parameter count.\n",
    "    Idea is: split up by direction. If travelling row-wise (eg d=(1, 0)), then split up by columns of origin. Then, by column, find all jumps in sorted list of rows.\n",
    "    '''\n",
    "    dict_perim = {d: [] for d in dirs}\n",
    "    for (x, y, d) in perim_set:  # split up by direction\n",
    "        dict_perim[d].append((x, y))\n",
    "\n",
    "    perim_count = 0 \n",
    "\n",
    "    for d, tiles in dict_perim.items():\n",
    "        if d[0] == 0:  # which tile is unique and which one should change. (Eg row-wise means row is unique and cols change)\n",
    "            ind_unique = 1\n",
    "            ind_other = 0\n",
    "        else:\n",
    "            ind_unique = 0\n",
    "            ind_other = 1\n",
    "\n",
    "        dict_tmp = defaultdict(list)\n",
    "        for t in tiles:  # split up by row/cols of origin\n",
    "            dict_tmp[t[ind_unique]].append(t[ind_other])\n",
    "\n",
    "        for _, ind_t_list in dict_tmp.items():\n",
    "            ind_t_list = sorted(ind_t_list)  # sort\n",
    "            perim_count += (1 + np.sum(np.diff(ind_t_list) > 1))  # count all jumps. So total is 1 perimeter per row/col of origin, per direction, plus any jumps.\n",
    "            # print(perim_count, d, _, ind_t_list)\n",
    "    \n",
    "    return perim_count\n",
    "\n",
    "total = 0\n",
    "for (region, perim_set) in regions:\n",
    "    new_perim = perim_converter(perim_set)\n",
    "    total += len(region) * new_perim\n",
    "\n",
    "total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
