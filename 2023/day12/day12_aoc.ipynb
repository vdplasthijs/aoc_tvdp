{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os, sys \n",
    "sys.path.append('..')\n",
    "import collections\n",
    "import copy\n",
    "from functools import cache \n",
    "import itertools\n",
    "import aoc_utils as au\n",
    "from tqdm import tqdm as tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['???.### 1,1,3',\n",
       " '.??..??...?##. 1,1,3',\n",
       " '?#?#?#?#?#?#?#? 1,3,1,6',\n",
       " '????.#...#... 4,1,1',\n",
       " '????.######..#####. 1,6,5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = au.read_txt_file_lines('input2.txt')\n",
    "n_rows = len(input_text)\n",
    "# n_cols = len(input_text[0])\n",
    "# for ii in range(1, n_rows):\n",
    "#     assert len(input_text[ii]) == n_cols, f'row {ii} has {len(input_text[ii])} cols, not {n_cols}'\n",
    "# print(f'input has {n_rows} rows and {n_cols} cols')\n",
    "input_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[data_row(locations='???.###', counts=[1, 1, 3]),\n",
       " data_row(locations='.??..??...?##.', counts=[1, 1, 3]),\n",
       " data_row(locations='?#?#?#?#?#?#?#?', counts=[1, 3, 1, 6]),\n",
       " data_row(locations='????.#...#...', counts=[4, 1, 1]),\n",
       " data_row(locations='????.######..#####.', counts=[1, 6, 5])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_row = collections.namedtuple('data_row', 'locations counts')\n",
    "list_data_rows = []\n",
    "list_n_qs = []\n",
    "for row in input_text:\n",
    "    assert '?' in row\n",
    "    tmp = row.split(' ')\n",
    "    assert len(tmp) == 2\n",
    "    locations = tmp[0] \n",
    "    counts = [int(x) for x in tmp[1].split(',')] \n",
    "    # print(locations, counts)\n",
    "    list_data_rows.append(data_row(locations, counts))    \n",
    "    list_n_qs.append(locations.count('?'))\n",
    "list_data_rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "def place_hashes(size, count):\n",
    "    '''with help from https://stackoverflow.com/questions/43816965/permutation-without-duplicates-in-python'''\n",
    "    for positions in itertools.combinations(range(size), count):\n",
    "        p = ['.'] * size\n",
    "        for i in positions:\n",
    "            p[i] = '#'\n",
    "        yield p\n",
    "\n",
    "def place_hashes_with_replacement(size, count):\n",
    "    '''with help from https://stackoverflow.com/questions/43816965/permutation-without-duplicates-in-python'''\n",
    "    for positions in itertools.combinations_with_replacement(range(size), count):\n",
    "        p = ['.'] * size\n",
    "        for i in positions:\n",
    "            p[i] = '#'\n",
    "        yield p\n",
    "\n",
    "def place_hashes_with_replacement_without_duplicates(size, max_count=5):\n",
    "    for count in range(np.minimum(size + 1, max_count)):\n",
    "        for positions in itertools.combinations(range(size), count):\n",
    "            p = ['.'] * size\n",
    "            for i in positions:\n",
    "                p[i] = '#'\n",
    "            yield p\n",
    "\n",
    "def check_sequence_correct(seq, counts):\n",
    "    ## assert seq is a string of .s and #s \n",
    "    assert type(seq) == str\n",
    "    assert set(seq).issubset(set('.#'))\n",
    "\n",
    "    ## check that the number of #s in seq matches the counts\n",
    "    seq_split = seq.split('.') \n",
    "    seq_count = [len(x) for x in seq_split if len(x) > 0]\n",
    "    return seq_count == counts\n",
    "\n",
    "def check_sequence_correct_fast(seq, counts):\n",
    "    ## check that the number of #s in seq matches the counts\n",
    "    seq_split = seq.split('.') \n",
    "    seq_count = [len(x) for x in seq_split if len(x) > 0]\n",
    "    return seq_count == counts\n",
    "\n",
    "def check_sequence_correct_faster(seq, counts):\n",
    "    seq_split = seq.split('.')\n",
    "    ii = 0\n",
    "    for x in seq_split:\n",
    "        if len(x) == 0:\n",
    "            continue \n",
    "        if ii >= len(counts) or len(x) != counts[ii]:\n",
    "            return False\n",
    "        ii += 1\n",
    "    return True\n",
    "\n",
    "# def check_sequence_correct_list(seq, counts):\n",
    "#     '''list of 0s and 1s'''\n",
    "#     group_counts = [sum(1 for _ in group) for key, group in itertools.groupby(seq) if key == '#']\n",
    "#     return group_counts == counts\n",
    "\n",
    "def check_sequence_correct_01(seq, counts):\n",
    "    '''list of 0s and 1s'''\n",
    "    group_counts = [sum(1 for _ in group) for key, group in itertools.groupby(seq) if key == 1]\n",
    "    return group_counts == counts\n",
    "\n",
    "def get_n_perms_per_seq(seq, counts, verbose=0):\n",
    "    assert '?' in seq\n",
    "    assert type(seq) == str\n",
    "    assert set(seq).issubset(set('.#?'))\n",
    "\n",
    "    n_hash = seq.count('#')\n",
    "    n_q = seq.count('?')\n",
    "    n_hash_counts = sum(counts) - n_hash  ## number of #s that need to be placed\n",
    "    n_dot_counts = n_q - n_hash_counts  ## number of .s that need to be placed\n",
    "    assert n_dot_counts >= 0, f'{n_dot_counts} < 0, {seq}, {counts}, {n_q}, {n_hash_counts}'\n",
    "    n_perms = 0\n",
    "    if verbose:\n",
    "        print(f'{n_dot_counts} dots, {n_hash_counts} hashes, {n_q} qs')\n",
    "    \n",
    "    for new_elements in place_hashes(n_q, n_hash_counts):  # generator of all possible combinations of #s and .s without duplicates \n",
    "        seq_try = list(seq)\n",
    "        for ii, char in enumerate(new_elements):\n",
    "            seq_try[seq_try.index('?')] = char\n",
    "        seq_try = ''.join(seq_try)\n",
    "        if check_sequence_correct_fast(seq_try, counts):\n",
    "            n_perms += 1\n",
    "    return n_perms\n",
    "\n",
    "def get_n_perms_per_row(row):\n",
    "    assert type(row) == data_row\n",
    "    return get_n_perms_per_seq(row.locations, row.counts)\n",
    "\n",
    "n_perm_total = 0 \n",
    "for row in list_data_rows:\n",
    "    # print(n_perm_total)\n",
    "    n_perm_total += get_n_perms_per_row(row)\n",
    "print(n_perm_total)\n",
    "# get_n_perms_per_seq(list_data_rows[0].locations, list_data_rows[0].counts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sequence_correct_fast('##..#....###...##....###.##.##', [2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sequence_correct_faster('##..#....###...##....###.##.##', [2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @cache\n",
    "def check_sequence_correct_fast_set(seq, counts):\n",
    "    ## check that the number of #s in seq matches the counts\n",
    "    seq_split = seq.split('.') \n",
    "    seq_count = set([len(x) for x in seq_split if len(x) > 0])\n",
    "    return seq_count == counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2 \n",
    "tricky .. \n",
    "**Could start going through special cases? **\n",
    "- (Note that the method above could be a lot faster if special cases were included via if statements, just to get down number of perms.. but is considerable effort)\n",
    "- If sequence ends with two `.`s, then the added `?` will always be a `.`, and hence, the total number of sequence perms will be the original number of perms `** 5`. \n",
    "- If not, then there will still be repetition! 4 times the same thing, plus an ending without extra `?` (plus spill-over into next sequence). \n",
    "- So maybe we can split up the new combined sequence in 2 parts: the first sequence + spill-over, and the remainder of the fifth part. Solve both. Then `perm_total = perm_1 ** 4 * perm_2`\n",
    "\n",
    "\n",
    "Okay plan is:\n",
    "1. Create new data structure, of `seq_1`, `count_1`, `seq_2`, `count_2`. (Merge, split past spill-over. Maybe use special cases of whether start/ends are `?` or not?)\n",
    "2. Solve both \n",
    "3. Combine perms \n",
    "\n",
    "**Update:**\n",
    "- Actually this is not perfect. Eg `..?..?..?.. [1,1]` first has 3 combinations, but in part 2 would have to be re-evaluated as a whole... (leading to (19, 10) permutations)\n",
    "\n",
    "Plan 2:\n",
    "- Could we consider trying out all connecting `?` possibilities separately? Those are 16 combinations. \n",
    "- I think the issue is the same; we cannot shortcut by considering original sequences separately and combining (the example above still fails). Maybe that example is too extreme.. but it seems kind of fruitless to code this up and run into some annoying sequence like that. \n",
    "\n",
    "Plan 3: \n",
    "- Going back to the start; can we start by filling in all the spots we know for sure? Ie one forward pass through all (combined) sequences and filling in all `?` that have just one possibility. That might massively bring down number of perms.\n",
    "- Secondly, if there are (large) contiguous groups of `?`, where we know for sure they must accomodate a large number of `#`, it would be brilliant if we could just take the (n, k) perm number and multiply instead of evaluating every combination of entire sequence .. \n",
    "\n",
    "Plan 4:\n",
    "- Go through the combined seq, holding ONLY 3 counts in memory. (Starting with the first 3). You only need to consider `sum(counts[:3])` existing `#` in seq. \n",
    "- See how many combis work.\n",
    "- Save those (number of perms) and go through sequence, multiplying cached n perms as you go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[data_row(locations='???.###????.###????.###????.###????.###', counts=[1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3]),\n",
       " data_row(locations='.??..??...?##.?.??..??...?##.?.??..??...?##.?.??..??...?##.?.??..??...?##.', counts=[1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3]),\n",
       " data_row(locations='?#?#?#?#?#?#?#???#?#?#?#?#?#?#???#?#?#?#?#?#?#???#?#?#?#?#?#?#???#?#?#?#?#?#?#?', counts=[1, 3, 1, 6, 1, 3, 1, 6, 1, 3, 1, 6, 1, 3, 1, 6, 1, 3, 1, 6]),\n",
       " data_row(locations='????.#...#...?????.#...#...?????.#...#...?????.#...#...?????.#...#...', counts=[4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1]),\n",
       " data_row(locations='????.######..#####.?????.######..#####.?????.######..#####.?????.######..#####.?????.######..#####.', counts=[1, 6, 5, 1, 6, 5, 1, 6, 5, 1, 6, 5, 1, 6, 5])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_rows_part2 = []\n",
    "n_repeats = 5\n",
    "for row in list_data_rows:\n",
    "    locations = '?'.join([row.locations] * n_repeats)\n",
    "    counts = row.counts * n_repeats \n",
    "    list_data_rows_part2.append(data_row(locations, counts))\n",
    "list_data_rows_part2[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_row_part2 = collections.namedtuple('data_row_part2', 'locations_1 counts_1 locations_2 counts_2')\n",
    "# list_data_rows_part2 = [] \n",
    "\n",
    "# for row in list_data_rows:\n",
    "#     print(row)\n",
    "#     start_char = row.locations[0]\n",
    "#     end_char = row.locations[-1] \n",
    "#     if start_char != '?' and end_char != '?': \n",
    "#         seq_1 = row.locations + '?'\n",
    "    \n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_n_perms_per_seq_part2(seq, counts, verbose=0):\n",
    "    assert '?' in seq\n",
    "    assert type(seq) == str\n",
    "    assert set(seq).issubset(set('.#?'))\n",
    "\n",
    "    n_hash = seq.count('#')\n",
    "    n_q = seq.count('?')\n",
    "    n_hash_counts = sum(counts) - n_hash  ## number of #s that need to be placed\n",
    "    n_dot_counts = n_q - n_hash_counts  ## number of .s that need to be placed\n",
    "    assert n_dot_counts >= 0, f'{n_dot_counts} < 0, {seq}, {counts}, {n_q}, {n_hash_counts}'\n",
    "    n_perms = 0\n",
    "    if verbose:\n",
    "        print(f'{n_dot_counts} dots, {n_hash_counts} hashes, {n_q} qs')\n",
    "    n_combis = math.factorial(n_q) / (math.factorial(n_hash_counts) * math.factorial(n_dot_counts))\n",
    "    print(f'{n_combis:.2e} combinations')\n",
    "    if n_combis > 1e8:\n",
    "        print('too many combinations')\n",
    "        return None\n",
    "    for new_elements in place_hashes(n_q, n_hash_counts):  # generator of all possible combinations of #s and .s without duplicates \n",
    "        seq_try = list(seq)\n",
    "        for ii, char in enumerate(new_elements):\n",
    "            seq_try[seq_try.index('?')] = char\n",
    "        seq_try = ''.join(seq_try)\n",
    "        if check_sequence_correct_fast(seq_try, counts):\n",
    "            n_perms += 1\n",
    "    return n_perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[data_row(locations='???.###????.###????.###????.###????.###', counts=[1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3]),\n",
       " data_row(locations='.??..??...?##.?.??..??...?##.?.??..??...?##.?.??..??...?##.?.??..??...?##.', counts=[1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3]),\n",
       " data_row(locations='?#?#?#?#?#?#?#???#?#?#?#?#?#?#???#?#?#?#?#?#?#???#?#?#?#?#?#?#???#?#?#?#?#?#?#?', counts=[1, 3, 1, 6, 1, 3, 1, 6, 1, 3, 1, 6, 1, 3, 1, 6, 1, 3, 1, 6]),\n",
       " data_row(locations='????.#...#...?????.#...#...?????.#...#...?????.#...#...?????.#...#...', counts=[4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1, 4, 1, 1]),\n",
       " data_row(locations='????.######..#####.?????.######..#####.?????.######..#####.?????.######..#####.?????.######..#####.', counts=[1, 6, 5, 1, 6, 5, 1, 6, 5, 1, 6, 5, 1, 6, 5])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_rows_part2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76e+12 combinations\n",
      "too many combinations\n"
     ]
    }
   ],
   "source": [
    "get_n_perms_per_seq_part2(list_data_rows_part2[2].locations, list_data_rows_part2[2].counts)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '.', '.', '.', '.']\n",
      "['#', '#', '.', '.', '.']\n",
      "['#', '.', '#', '.', '.']\n",
      "['#', '.', '.', '#', '.']\n",
      "['#', '.', '.', '.', '#']\n",
      "['#', '#', '.', '.', '.']\n",
      "['#', '#', '#', '.', '.']\n",
      "['#', '#', '.', '#', '.']\n",
      "['#', '#', '.', '.', '#']\n",
      "['#', '.', '#', '.', '.']\n",
      "['#', '.', '#', '#', '.']\n",
      "['#', '.', '#', '.', '#']\n",
      "['#', '.', '.', '#', '.']\n",
      "['#', '.', '.', '#', '#']\n",
      "['#', '.', '.', '.', '#']\n",
      "['#', '#', '.', '.', '.']\n",
      "['#', '#', '#', '.', '.']\n",
      "['#', '#', '.', '#', '.']\n",
      "['#', '#', '.', '.', '#']\n",
      "['#', '#', '#', '.', '.']\n",
      "['#', '#', '#', '#', '.']\n",
      "['#', '#', '#', '.', '#']\n",
      "['#', '#', '.', '#', '.']\n",
      "['#', '#', '.', '#', '#']\n",
      "['#', '#', '.', '.', '#']\n",
      "['#', '.', '#', '.', '.']\n",
      "['#', '.', '#', '#', '.']\n",
      "['#', '.', '#', '.', '#']\n",
      "['#', '.', '#', '#', '.']\n",
      "['#', '.', '#', '#', '#']\n",
      "['#', '.', '#', '.', '#']\n",
      "['#', '.', '.', '#', '.']\n",
      "['#', '.', '.', '#', '#']\n",
      "['#', '.', '.', '#', '#']\n",
      "['#', '.', '.', '.', '#']\n",
      "['#', '#', '.', '.', '.']\n",
      "['#', '#', '#', '.', '.']\n",
      "['#', '#', '.', '#', '.']\n",
      "['#', '#', '.', '.', '#']\n",
      "['#', '#', '#', '.', '.']\n",
      "['#', '#', '#', '#', '.']\n",
      "['#', '#', '#', '.', '#']\n",
      "['#', '#', '.', '#', '.']\n",
      "['#', '#', '.', '#', '#']\n",
      "['#', '#', '.', '.', '#']\n",
      "['#', '#', '#', '.', '.']\n",
      "['#', '#', '#', '#', '.']\n",
      "['#', '#', '#', '.', '#']\n",
      "['#', '#', '#', '#', '.']\n",
      "['#', '#', '#', '#', '#']\n",
      "['#', '#', '#', '.', '#']\n",
      "['#', '#', '.', '#', '.']\n",
      "['#', '#', '.', '#', '#']\n",
      "['#', '#', '.', '#', '#']\n",
      "['#', '#', '.', '.', '#']\n",
      "['#', '.', '#', '.', '.']\n",
      "['#', '.', '#', '#', '.']\n",
      "['#', '.', '#', '.', '#']\n",
      "['#', '.', '#', '#', '.']\n",
      "['#', '.', '#', '#', '#']\n",
      "['#', '.', '#', '.', '#']\n",
      "['#', '.', '#', '#', '.']\n",
      "['#', '.', '#', '#', '#']\n",
      "['#', '.', '#', '#', '#']\n",
      "['#', '.', '#', '.', '#']\n",
      "['#', '.', '.', '#', '.']\n",
      "['#', '.', '.', '#', '#']\n",
      "['#', '.', '.', '#', '#']\n",
      "['#', '.', '.', '#', '#']\n",
      "['#', '.', '.', '.', '#']\n",
      "['.', '#', '.', '.', '.']\n",
      "['.', '#', '#', '.', '.']\n",
      "['.', '#', '.', '#', '.']\n",
      "['.', '#', '.', '.', '#']\n",
      "['.', '#', '#', '.', '.']\n",
      "['.', '#', '#', '#', '.']\n",
      "['.', '#', '#', '.', '#']\n",
      "['.', '#', '.', '#', '.']\n",
      "['.', '#', '.', '#', '#']\n",
      "['.', '#', '.', '.', '#']\n",
      "['.', '#', '#', '.', '.']\n",
      "['.', '#', '#', '#', '.']\n",
      "['.', '#', '#', '.', '#']\n",
      "['.', '#', '#', '#', '.']\n",
      "['.', '#', '#', '#', '#']\n",
      "['.', '#', '#', '.', '#']\n",
      "['.', '#', '.', '#', '.']\n",
      "['.', '#', '.', '#', '#']\n",
      "['.', '#', '.', '#', '#']\n",
      "['.', '#', '.', '.', '#']\n",
      "['.', '#', '#', '.', '.']\n",
      "['.', '#', '#', '#', '.']\n",
      "['.', '#', '#', '.', '#']\n",
      "['.', '#', '#', '#', '.']\n",
      "['.', '#', '#', '#', '#']\n",
      "['.', '#', '#', '.', '#']\n",
      "['.', '#', '#', '#', '.']\n",
      "['.', '#', '#', '#', '#']\n",
      "['.', '#', '#', '#', '#']\n",
      "['.', '#', '#', '.', '#']\n",
      "['.', '#', '.', '#', '.']\n",
      "['.', '#', '.', '#', '#']\n",
      "['.', '#', '.', '#', '#']\n",
      "['.', '#', '.', '#', '#']\n",
      "['.', '#', '.', '.', '#']\n",
      "['.', '.', '#', '.', '.']\n",
      "['.', '.', '#', '#', '.']\n",
      "['.', '.', '#', '.', '#']\n",
      "['.', '.', '#', '#', '.']\n",
      "['.', '.', '#', '#', '#']\n",
      "['.', '.', '#', '.', '#']\n",
      "['.', '.', '#', '#', '.']\n",
      "['.', '.', '#', '#', '#']\n",
      "['.', '.', '#', '#', '#']\n",
      "['.', '.', '#', '.', '#']\n",
      "['.', '.', '#', '#', '.']\n",
      "['.', '.', '#', '#', '#']\n",
      "['.', '.', '#', '#', '#']\n",
      "['.', '.', '#', '#', '#']\n",
      "['.', '.', '#', '.', '#']\n",
      "['.', '.', '.', '#', '.']\n",
      "['.', '.', '.', '#', '#']\n",
      "['.', '.', '.', '#', '#']\n",
      "['.', '.', '.', '#', '#']\n",
      "['.', '.', '.', '#', '#']\n",
      "['.', '.', '.', '.', '#']\n"
     ]
    }
   ],
   "source": [
    "for ii in place_hashes_with_replacement(5, 5):\n",
    "    print(ii)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split combined seq up in segments split by `.`\n",
    "- for each, compute possible list of `#` counts (with cache) => create a namedtuple that has `(counts, n_combs)` (eg both `#..#` and `#.#.` make `counts=[1,1], n_combs=2)`)\n",
    "- discard any of these where `max(counts) > max(seq_counts)`\n",
    "- (maybe: discard if pattern does NOT occur in seq)\n",
    "- Then, start combining all possible segment counts and see which ones work. Multiply `n_combs` of each. (In some kind of tree/recursive manner: start from front and discard each segment once its a mismatch). Maybe there is a quick look up table? Something like, once you have matched the first 3, pop them from the front of the seg_count list, and then match the next first elements. (so `seg_count == seq_count[:len(seg_count)]`)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_possibilities = collections.namedtuple('counts_possibilities', 'counts n_possible')\n",
    "\n",
    "def lookup_all_count_possibilities_sequence(seq, max_total_count=5):\n",
    "    seq_split = seq.split('.') \n",
    "    list_seg_counts = []\n",
    "    n_hash = seq.count('#')\n",
    "    for segment in seq_split:\n",
    "        if len(segment) > 0:\n",
    "            list_possible_counts_segment = possible_counts_segment(segment, max_count=max_total_count - n_hash)\n",
    "            # print(list_possible_counts_segment)\n",
    "            list_seg_counts.append(list_possible_counts_segment)\n",
    "    return list_seg_counts\n",
    "\n",
    "@cache        \n",
    "def possible_counts_segment(segment, max_count=5):\n",
    "    n_hash = segment.count('#')\n",
    "    n_q = segment.count('?')\n",
    "    dict_pos = {}\n",
    "    \n",
    "    for new_elements in place_hashes_with_replacement_without_duplicates(n_q, max_count=max_count):\n",
    "        segment_try = list(segment)\n",
    "        for ii, char in enumerate(new_elements):\n",
    "            segment_try[segment_try.index('?')] = char\n",
    "        segment_try = ''.join(segment_try)\n",
    "        n_hash_counts = [len(x) for x in segment_try.split('.') if len(x) > 0]\n",
    "        n_hash_counts = '-'.join([str(x) for x in n_hash_counts])\n",
    "        if n_hash_counts not in dict_pos:\n",
    "            dict_pos[n_hash_counts] = 1 \n",
    "        else:\n",
    "            dict_pos[n_hash_counts] += 1 \n",
    "    seg_count = []\n",
    "    for key in dict_pos:\n",
    "        if key == '':\n",
    "            counts = []\n",
    "        else:\n",
    "            counts = [int(x) for x in key.split('-')]\n",
    "        seg_count.append(counts_possibilities(counts, dict_pos[key]))\n",
    "    return seg_count\n",
    "    \n",
    "def calculate_possibilities_count_sequence(seq, count):\n",
    "    list_seg_counts = lookup_all_count_possibilities_sequence(seq)\n",
    "    n_possibilities = 0 \n",
    "    n_ops = np.prod([len(x) for x in list_seg_counts])\n",
    "\n",
    "\n",
    "    return n_possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_n_ops = []\n",
    "# for row in tqdm(list_data_rows_part2):\n",
    "#     tmp = lookup_all_count_possibilities_sequence(row.locations)\n",
    "#     n_ops = np.prod([len(x) for x in tmp])\n",
    "#     list_n_ops.append(n_ops)\n",
    "i_row = 4\n",
    "tmp = lookup_all_count_possibilities_sequence(list_data_rows_part2[i_row].locations, \n",
    "                                              max_total_count=sum(list_data_rows_part2[i_row].counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 1, 1, 12, 1, 1, 12, 1, 1, 12, 1, 1, 12, 1, 1] 165888\n"
     ]
    }
   ],
   "source": [
    "print([len(x) for x in tmp], np.prod([len(x) for x in tmp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_row(locations='????.######..#####.?????.######..#####.?????.######..#####.?????.######..#####.?????.######..#####.', counts=[1, 6, 5, 1, 6, 5, 1, 6, 5, 1, 6, 5, 1, 6, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_rows_part2[i_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[counts_possibilities(counts=[], n_possible=1),\n",
       " counts_possibilities(counts=[1], n_possible=4),\n",
       " counts_possibilities(counts=[2], n_possible=3),\n",
       " counts_possibilities(counts=[1, 1], n_possible=3),\n",
       " counts_possibilities(counts=[3], n_possible=2),\n",
       " counts_possibilities(counts=[2, 1], n_possible=1),\n",
       " counts_possibilities(counts=[1, 2], n_possible=1),\n",
       " counts_possibilities(counts=[4], n_possible=1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_counts_segment('????')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
